{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_VOCAB = 10 # BERT tokenizer uses single tokens for these numericals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data):\n",
    "  \"Shuffling the data randomly\"\n",
    "  indices = np.array(range(len(data)))\n",
    "  np.random.shuffle(indices)\n",
    "  return data[indices]\n",
    "\n",
    "def split_data(data, train_ratio=0.8):\n",
    "  \"Spliting the data into training and validation sets accoring to some ratio.\"\n",
    "  n_train = int(len(data) * train_ratio)\n",
    "  train_data = data[:n_train]\n",
    "  val_data = data[n_train:]\n",
    "  return train_data, val_data\n",
    "\n",
    "def add_ground_truths(data):\n",
    "    \"Adding the ground truth labels to the data. In this case the maximum of the row\"\n",
    "    maximum = torch.max(data, dim=1).values\n",
    "    res = torch.concat((data,maximum.unsqueeze(1)), axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1:\n",
    "\n",
    "We generate training and test data, without allowing that the exact same list appears in both sets. Trivial lists [x,x] are included.\n",
    "\n",
    "Example:    if [3,2] in train => [3,2] not in test <br>\n",
    "            if [3,2] in train => [2,3] can be in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_1(n_digits=D_VOCAB, sequence_length=2):\n",
    "  \"Generating exhaustive list of two numbers using the Cartesian product of [0,...,n_digits]\"\n",
    "  data = list(itertools.product(range(n_digits+1), repeat=sequence_length))\n",
    "  data = torch.tensor(data)\n",
    "  return data\n",
    "\n",
    "def generate_data_1(n_digits=D_VOCAB, sequence_length=2, train_ratio=0.8):\n",
    "  \"Generating the train and validation data. No same lists will appear in both sets.\"\n",
    "  data = create_data_1(n_digits, sequence_length)\n",
    "  data = shuffle_data(data)\n",
    "  train_data, val_data = split_data(data, train_ratio)\n",
    "  return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 2],\n",
       "         [0, 1],\n",
       "         [0, 2],\n",
       "         [2, 2],\n",
       "         [2, 1],\n",
       "         [2, 0],\n",
       "         [0, 0],\n",
       "         [3, 0],\n",
       "         [1, 0],\n",
       "         [1, 1],\n",
       "         [0, 3]]),\n",
       " tensor([[2, 3],\n",
       "         [3, 3],\n",
       "         [1, 3],\n",
       "         [3, 1]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2:\n",
    "We generate training and test data without allowing that a permuted list appears in both sets.\n",
    "\n",
    "Example: if [2,3] in train => [3,2] not in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1, 1],\n",
      "        [1, 0],\n",
      "        [2, 3],\n",
      "        [2, 2],\n",
      "        [2, 1],\n",
      "        [1, 2],\n",
      "        [3, 2],\n",
      "        [1, 3],\n",
      "        [0, 1],\n",
      "        [3, 1],\n",
      "        [3, 3]]), tensor([[0, 2],\n",
      "        [3, 0],\n",
      "        [2, 0],\n",
      "        [0, 3],\n",
      "        [0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "def create_data_2(n_digits=D_VOCAB, sequence_length=2):\n",
    "    \"Generating combinations of two numbers without permutations\"\n",
    "    data = list(itertools.combinations(range(n_digits+1), sequence_length))\n",
    "    data = torch.tensor(data)\n",
    "    return data\n",
    "\n",
    "def add_permutations_2(train_data, val_data):\n",
    "    \"Adding permutations after train-test split.\"\n",
    "    permuted_train_data = train_data[:,[1,0]]\n",
    "    permuted_val_data = val_data[:,[1,0]]\n",
    "    new_train_data = torch.concat((train_data, permuted_train_data), axis=0)\n",
    "    new_test_data = torch.concat((val_data, permuted_val_data), axis=0)\n",
    "    return new_train_data, new_test_data\n",
    "\n",
    "def add_same_numbers_2(n_digits,train_data, val_data, train_ratio=0.8):\n",
    "    \"Adding same number lists [x,x] to train and test sets.\"\n",
    "\n",
    "    # Create a list of same number lists [x,x]\n",
    "    numbers = torch.tensor(range(n_digits+1)).unsqueeze(1)\n",
    "    same_number_lists = torch.cat((numbers, numbers), axis=1)\n",
    "\n",
    "    # Shuffle the list\n",
    "    indices = np.array(range(len(same_number_lists)))\n",
    "    np.random.shuffle(indices)\n",
    "    same_number_lists = same_number_lists[indices]\n",
    "\n",
    "    # Add them proportionally to train and test sets\n",
    "    n_train = int(len(same_number_lists) * train_ratio)\n",
    "    train_data = torch.concat((train_data, same_number_lists[:n_train]), axis=0)\n",
    "    val_data = torch.concat((val_data, same_number_lists[n_train:]), axis=0)\n",
    "    return train_data, val_data\n",
    "\n",
    "def generate_data_2(n_digits=D_VOCAB, sequence_length=2, train_ratio=0.8):\n",
    "    \"Generating the train and validation data. No same lists will appear in both sets.\"\n",
    "    data = create_data_2(n_digits, sequence_length)\n",
    "    data = shuffle_data(data)\n",
    "    train_data, val_data = split_data(data, train_ratio)\n",
    "    train_data, val_data = add_permutations_2(train_data, val_data)\n",
    "    train_data, val_data = add_same_numbers_2(n_digits, train_data, val_data, train_ratio)\n",
    "    train_data = shuffle_data(train_data)\n",
    "    val_data = shuffle_data(val_data)\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [0, 0],\n",
       "         [2, 3],\n",
       "         [1, 2],\n",
       "         [3, 0],\n",
       "         [0, 3],\n",
       "         [1, 0],\n",
       "         [2, 2],\n",
       "         [2, 1],\n",
       "         [3, 2],\n",
       "         [3, 3]]),\n",
       " tensor([[1, 1],\n",
       "         [0, 2],\n",
       "         [3, 1],\n",
       "         [2, 0],\n",
       "         [1, 3]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "\n",
    "We generate training and test data without allowing that one number can appear both in train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 1,  4],\n",
      "        [ 9,  9],\n",
      "        [ 4,  7],\n",
      "        [ 7, 10],\n",
      "        [ 9,  5],\n",
      "        [10,  0],\n",
      "        [ 1,  1],\n",
      "        [ 0,  7],\n",
      "        [ 6,  0],\n",
      "        [10,  9],\n",
      "        [ 6,  6],\n",
      "        [ 1,  9],\n",
      "        [ 0,  5],\n",
      "        [ 5,  6],\n",
      "        [ 4,  9],\n",
      "        [ 7,  4],\n",
      "        [10,  6],\n",
      "        [ 0,  1],\n",
      "        [10,  5],\n",
      "        [ 5,  4],\n",
      "        [10,  1],\n",
      "        [ 9,  6],\n",
      "        [10,  7],\n",
      "        [10, 10],\n",
      "        [ 9,  7],\n",
      "        [ 4,  6],\n",
      "        [ 4, 10],\n",
      "        [ 6,  4],\n",
      "        [ 6,  7],\n",
      "        [ 5,  0],\n",
      "        [ 6,  9],\n",
      "        [ 9,  4],\n",
      "        [ 6,  5],\n",
      "        [ 5,  9],\n",
      "        [ 0,  6],\n",
      "        [ 1,  7],\n",
      "        [ 0,  4],\n",
      "        [ 0, 10],\n",
      "        [ 0,  0],\n",
      "        [ 1,  6],\n",
      "        [ 7,  7],\n",
      "        [10,  4],\n",
      "        [ 6,  1],\n",
      "        [ 6, 10],\n",
      "        [ 4,  4],\n",
      "        [ 0,  9],\n",
      "        [ 1,  5],\n",
      "        [ 1, 10],\n",
      "        [ 9, 10],\n",
      "        [ 7,  5],\n",
      "        [ 4,  1],\n",
      "        [ 4,  5],\n",
      "        [ 5, 10],\n",
      "        [ 7,  6],\n",
      "        [ 7,  9],\n",
      "        [ 7,  1],\n",
      "        [ 1,  0],\n",
      "        [ 9,  0],\n",
      "        [ 7,  0],\n",
      "        [ 5,  7],\n",
      "        [ 9,  1],\n",
      "        [ 5,  5],\n",
      "        [ 4,  0],\n",
      "        [ 5,  1]], dtype=torch.int32), tensor([[2, 2],\n",
      "        [8, 2],\n",
      "        [3, 2],\n",
      "        [8, 8],\n",
      "        [2, 3],\n",
      "        [8, 3],\n",
      "        [3, 8],\n",
      "        [2, 8],\n",
      "        [3, 3]], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "def create_data_3(n_digits=D_VOCAB, sequence_length=2):\n",
    "    data = np.array(range(n_digits+1))\n",
    "    return data\n",
    "\n",
    "def generate_data_3(n_digits=D_VOCAB, sequence_length=2, train_ratio=0.8):\n",
    "    data = create_data_3(n_digits, sequence_length)\n",
    "    data = shuffle_data(data)\n",
    "    train_data, val_data = split_data(data, train_ratio)\n",
    "    train_data, val_data = create_data_4(train_data, val_data)\n",
    "    train_data = shuffle_data(train_data)\n",
    "    val_data = shuffle_data(val_data)\n",
    "    return train_data, val_data\n",
    "\n",
    "def create_data_4(train_data, val_data):\n",
    "    train_data = list(itertools.product(train_data, repeat=2))\n",
    "    val_data = list(itertools.product(val_data, repeat=2))\n",
    "    train_data = torch.tensor(train_data)\n",
    "    val_data = torch.tensor(val_data)\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 1],\n",
       "         [0, 2],\n",
       "         [8, 7],\n",
       "         [7, 8],\n",
       "         [2, 0],\n",
       "         [9, 5],\n",
       "         [5, 2],\n",
       "         [9, 7],\n",
       "         [1, 4],\n",
       "         [8, 4],\n",
       "         [7, 9],\n",
       "         [1, 1],\n",
       "         [0, 8],\n",
       "         [7, 7],\n",
       "         [2, 7],\n",
       "         [5, 1],\n",
       "         [4, 7],\n",
       "         [9, 2],\n",
       "         [0, 1],\n",
       "         [5, 0],\n",
       "         [7, 1],\n",
       "         [1, 2],\n",
       "         [8, 8],\n",
       "         [8, 2],\n",
       "         [0, 7],\n",
       "         [5, 7],\n",
       "         [5, 8],\n",
       "         [1, 9],\n",
       "         [9, 9],\n",
       "         [2, 8],\n",
       "         [7, 0],\n",
       "         [2, 2],\n",
       "         [0, 5],\n",
       "         [7, 4],\n",
       "         [8, 0],\n",
       "         [0, 9],\n",
       "         [2, 9],\n",
       "         [9, 4],\n",
       "         [4, 4],\n",
       "         [9, 0],\n",
       "         [0, 4],\n",
       "         [9, 8],\n",
       "         [5, 4],\n",
       "         [1, 8],\n",
       "         [5, 9],\n",
       "         [4, 0],\n",
       "         [4, 9],\n",
       "         [4, 5],\n",
       "         [1, 7],\n",
       "         [8, 9],\n",
       "         [7, 2],\n",
       "         [7, 5],\n",
       "         [2, 4],\n",
       "         [0, 0],\n",
       "         [9, 1],\n",
       "         [1, 5],\n",
       "         [1, 0],\n",
       "         [4, 8],\n",
       "         [2, 1],\n",
       "         [8, 1],\n",
       "         [5, 5],\n",
       "         [2, 5],\n",
       "         [8, 5],\n",
       "         [4, 2]], dtype=torch.int32),\n",
       " tensor([[10,  3],\n",
       "         [ 6,  6],\n",
       "         [ 3,  6],\n",
       "         [ 6, 10],\n",
       "         [ 6,  3],\n",
       "         [10, 10],\n",
       "         [ 3,  3],\n",
       "         [10,  6],\n",
       "         [ 3, 10]], dtype=torch.int32))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse to CSV files\n",
    "The format is:\n",
    "input, output\n",
    "\n",
    "Example:\n",
    " \"[ 296, 34 ]\", \"296\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train_data_to_csv(data, file_name):\n",
    "\n",
    "    # Convert to numpy array\n",
    "    data = data.numpy()\n",
    "\n",
    "    parsed_inputs = []\n",
    "    for row in data:\n",
    "        # Create a regular expression pattern for the current row\n",
    "        pattern = r'START {} {} STOP [MASK]'.format(''.join(str(row[0])), str(row[1]))\n",
    "        parsed_inputs.append(pattern)\n",
    "\n",
    "    parsed_outputs = []\n",
    "    for row in data:\n",
    "        # Create a regular expression pattern for the current row\n",
    "        pattern = r'{}'.format(''.join(str(row[2])))\n",
    "        parsed_outputs.append(pattern)\n",
    "\n",
    "    # Create a DataFrame from the parsed rows\n",
    "    df = pd.DataFrame()\n",
    "    df['input'] = parsed_inputs\n",
    "    df['output'] = parsed_outputs\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "tensor = torch.tensor([[2,3,3],[3,6,6],[8,10,10]])\n",
    "parse_train_data_to_csv(tensor, \"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
